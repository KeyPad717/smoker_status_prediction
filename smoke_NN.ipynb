{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4ed421",
   "metadata": {},
   "source": [
    "# Smoker Status Prediction - Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec7ca3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd15835",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441b6af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (38984, 23)\n",
      "Test dataset shape: (16708, 22)\n",
      "Preprocessing complete with RobustScaler.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv('train_dataset.csv')\n",
    "test_df = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "print(f\"Train dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")\n",
    "\n",
    "if train_df.duplicated().sum() > 0:\n",
    "    train_df = train_df.drop_duplicates()\n",
    "\n",
    "skewed_cols = [\n",
    "    'triglyceride', 'LDL', 'Gtp',\n",
    "    'AST', 'ALT', 'serum creatinine',\n",
    "    'fasting blood sugar'\n",
    "]\n",
    "\n",
    "for col in skewed_cols:\n",
    "    train_df[col] = np.log1p(train_df[col])\n",
    "    test_df[col] = np.log1p(test_df[col])\n",
    "\n",
    "X = train_df.drop('smoking', axis=1)\n",
    "y = train_df['smoking']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "test_scaled = scaler.transform(test_df)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X.columns)\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=test_df.columns)\n",
    "\n",
    "print(\"Preprocessing complete with RobustScaler.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8dfd9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.75560\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      4242\n",
      "           1       0.66      0.67      0.67      2452\n",
      "\n",
      "    accuracy                           0.76      6694\n",
      "   macro avg       0.74      0.74      0.74      6694\n",
      "weighted avg       0.76      0.76      0.76      6694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128),   \n",
    "    activation='logistic',          \n",
    "    solver='adam',               \n",
    "    learning_rate='constant',\n",
    "    max_iter=100,               \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df3ad2",
   "metadata": {},
   "source": [
    "i tried multiple max iterations and 100 gave me the best accuracy as it's more or less significant number of iterations, after some manual tunings i found out that adam and sgd gave the best solver's accuracy, so i though of running them both for better accuracy, also i saw that adam solver with logistic or sigmoid activation function was giving the best accuracy\n",
    "adding more layers in Neural Network to increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27fda422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.75426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      4242\n",
      "           1       0.65      0.71      0.68      2452\n",
      "\n",
      "    accuracy                           0.75      6694\n",
      "   macro avg       0.74      0.75      0.74      6694\n",
      "weighted avg       0.76      0.75      0.76      6694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64,32),   \n",
    "    activation='logistic',          \n",
    "    solver='adam',               \n",
    "    learning_rate='constant',\n",
    "    max_iter=100,               \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccb8543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.75710\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      4242\n",
      "           1       0.67      0.68      0.67      2452\n",
      "\n",
      "    accuracy                           0.76      6694\n",
      "   macro avg       0.74      0.74      0.74      6694\n",
      "weighted avg       0.76      0.76      0.76      6694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64),   \n",
    "    activation='logistic',          \n",
    "    solver='adam',               \n",
    "    learning_rate='constant',\n",
    "    max_iter=100,               \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8274da79",
   "metadata": {},
   "source": [
    "we can see that increasing layers does not increase the accuracy everytime, as the dataset is small and not complex enough to require multiple layers and so deeper model overfit quickly.\n",
    "Based on above observations, i'll do an optuna seatch in order to tune the best hyperparameters and to get the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a09cf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Validation Accuracy: 0.75471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      4242\n",
      "           1       0.65      0.71      0.68      2452\n",
      "\n",
      "    accuracy                           0.75      6694\n",
      "   macro avg       0.74      0.75      0.74      6694\n",
      "weighted avg       0.76      0.75      0.76      6694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(256,128),   \n",
    "    activation='logistic',          \n",
    "    solver='adam',               \n",
    "    learning_rate='constant',\n",
    "    max_iter=100,               \n",
    "    random_state=42,\n",
    "    alpha=1e-4\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_nn = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(f\"NN Validation Accuracy: {accuracy_score(y_val, y_pred_nn):.5f}\")\n",
    "print(classification_report(y_val, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27838cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7463126843657817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      4933\n",
      "           1       0.65      0.66      0.66      2864\n",
      "\n",
      "    accuracy                           0.75      7797\n",
      "   macro avg       0.73      0.73      0.73      7797\n",
      "weighted avg       0.75      0.75      0.75      7797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iiitb/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "train_df = pd.read_csv(\"train_dataset.csv\")\n",
    "\n",
    "train_df[\"BMI\"] = train_df[\"weight(kg)\"] / ((train_df[\"height(cm)\"] / 100) ** 2)\n",
    "train_df[\"chol_ratio\"] = train_df[\"LDL\"] / train_df[\"HDL\"]\n",
    "train_df[\"liver_ratio\"] = train_df[\"Gtp\"] / train_df[\"ALT\"]\n",
    "train_df[\"sugar_liver\"] = train_df[\"fasting blood sugar\"] / train_df[\"Gtp\"]\n",
    "train_df[\"age_group\"] = pd.cut(train_df[\"age\"], bins=[0,30,40,50,60,100], labels=[1,2,3,4,5])\n",
    "\n",
    "X = train_df.drop(\"smoking\", axis=1)\n",
    "y = train_df[\"smoking\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,64),\n",
    "    activation='logistic',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "pred = nn_model.predict(X_val_scaled)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, pred))\n",
    "print(classification_report(y_val, pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
